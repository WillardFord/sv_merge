{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Clustering from Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have limited performance when counting the number of correct edges against the number of faulty edges. However, this does not indicate that we have poor performance when evaluating out clusters. Even though we have some proportion of faulty edges, due to our high number of correct edges we might have a strong ability to cluster sequences. Let's try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we'll need adjacency matrices. Let's test the performance in a single region first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from itertools import repeat\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib\n",
    "import random\n",
    "\n",
    "import math\n",
    "from scipy.linalg import *\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.cluster import SpectralCoclustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. sketch with k = 20 roughly\n",
    "2. euclidean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert from numpy array to pandas df for plotting\n",
    "\"\"\"\n",
    "def numpy_counts_to_pandas(array):\n",
    "    df = pd.DataFrame()\n",
    "    df[\"true_pos\"] = array[0,:]\n",
    "    df[\"tot_pos\"] = array[1,:]\n",
    "    df[\"false_pos\"] = array[2,:]\n",
    "    df[\"tot_neg\"] = array[3,:]\n",
    "\n",
    "    df[\"tpr\"] = df[\"true_pos\"] / df[\"tot_pos\"]\n",
    "    df[\"fpr\"] = df[\"false_pos\"] / df[\"tot_neg\"]\n",
    "    df[\"band_size\"] = range(1,500)\n",
    "\n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "Plot the ROC curve\n",
    "\"\"\"\n",
    "def plotROC(df, title = \"ROC Curve\"):\n",
    "    bands = df[\"band_size\"]\n",
    "    tprs = df[\"tpr\"]\n",
    "    fprs = df[\"fpr\"]\n",
    "\n",
    "    #area_under_curve = auc(fprs, tprs)\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.scatter(fprs, tprs, c = bands, marker = \".\")\n",
    "    num_labels = min(10, len(bands))\n",
    "    scale = int(len(bands)//num_labels)\n",
    "    for i in range(num_labels):\n",
    "        index = i*scale\n",
    "        ax.text(fprs[index], tprs[index]+0.05, bands[index])\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc = \"lower right\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Plot the ROC curve for multiple different paramters\n",
    "\"\"\"\n",
    "def plotROCwithParams(dfs, params, title = \"ROC Curve with params\", param_header = \"\"):\n",
    "    if len(dfs) is not len(params):\n",
    "        print(\"Number of inputs and parameters is not the same!\")\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Add y=x line\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "    cmap = matplotlib.cm.get_cmap('plasma')\n",
    "    norm = plt.Normalize(vmin=0, vmax=len(params))\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "        bands = df[\"band_size\"]\n",
    "        tprs = df[\"tpr\"]\n",
    "        fprs = df[\"fpr\"]\n",
    "\n",
    "        # Plot the ROC curve\n",
    "        plt.scatter(fprs, tprs, \n",
    "                    c = cmap(norm(i)), \n",
    "                    marker = \".\",\n",
    "                    label= param_header + f\"{params[i]}\"\n",
    "        )\n",
    "\n",
    "        # Add AUC label TODO\n",
    "        #area_under_curve = auc(fprs, tprs)\n",
    "\n",
    "        # Add band size labels\n",
    "        #num_labels = min(10, len(bands))\n",
    "        #scale = int(len(bands)//num_labels)\n",
    "        #for i in range(num_labels):\n",
    "        #    index = i*scale\n",
    "        #    ax.text(fprs[index], tprs[index]+0.05, bands[index])\n",
    "\n",
    "    plt.legend(loc = \"upper left\", bbox_to_anchor = (1,0,.5,1))\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Returns sorted seqs and labels by labels from fastq file\n",
    "\"\"\"\n",
    "def readFastq(fastqFile:str):\n",
    "    seqs :list[str] = []\n",
    "    labels :list[str] = []\n",
    "    with open(fastqFile,\"r\") as f:\n",
    "        i = 0\n",
    "        curHap = -1\n",
    "        for line in f.readlines():\n",
    "            if i % 4 == 0:\n",
    "                for segment in line.strip().split(\" \"):\n",
    "                    if segment.startswith(\"HP\"):\n",
    "                        curHap = segment.split(\":\")[-1]\n",
    "            elif i % 4 == 1:\n",
    "                if curHap == -1:\n",
    "                    continue\n",
    "                curSeq = line.strip()\n",
    "                seqs.append(curSeq)\n",
    "                labels.append(curHap)\n",
    "                curHap = -1\n",
    "                curSeq = \"\"\n",
    "            i += 1\n",
    "    seqs, labels = zip(*sorted(zip(seqs, labels), key = lambda x : x[1]))\n",
    "    return seqs, labels\n",
    "\n",
    "\"\"\"\n",
    "Iterate over all band sizes for a single region. Called in parallel over every region at once.\n",
    "\"\"\"\n",
    "def test_bands(signature_matrix_directory, file, band_sizes, include_length = False, include_hash = False):\n",
    "\n",
    "    signature_matrix = np.load(os.path.join(signature_matrix_directory, file))\n",
    "    labels = signature_matrix[0,:].astype('int8')\n",
    "    signature_matrix = signature_matrix[1:,:]\n",
    "\n",
    "    if include_length or type(include_hash) is int:\n",
    "        fastq_file = os.path.join(\"../../../output/HG002_20bp/all_chr/\", file[:-3]) + \"fastq\"\n",
    "        seqs, _ = readFastq(fastq_file)\n",
    "        lengths = [len(x) for x in seqs]\n",
    "        if 0 in lengths:\n",
    "            return 0\n",
    "    else:\n",
    "        seqs = None\n",
    "        lengths = None\n",
    "\n",
    "    # Return Adjacency Matrix in this case\n",
    "    if type(band_sizes) is int:\n",
    "        adjacency_matrix = tprSignatureMatrix(signature_matrix, band_sizes, labels, include_length, \n",
    "            include_hash, seqs, lengths, want_adjacency_matrix = True)\n",
    "        return adjacency_matrix, labels\n",
    "    # Return TPR FPR information\n",
    "    else:\n",
    "        counts = np.zeros((4, len(band_sizes)), dtype = int)\n",
    "        for band_size in band_sizes:\n",
    "            counts[:,band_size-1] = tprSignatureMatrix(\n",
    "                signature_matrix, \n",
    "                band_size, \n",
    "                labels, \n",
    "                include_length = include_length, \n",
    "                include_hash = include_hash, \n",
    "                seqs = seqs,\n",
    "                lengths = lengths\n",
    "            )\n",
    "        return counts\n",
    "\n",
    "\"\"\"\n",
    "Generate TPR and FPR for a given signature matrix, band length, and label list\n",
    "Returns [test_pos, tot_pos, test_neg, tot_neg]\n",
    "\"\"\"\n",
    "def tprSignatureMatrix(signature_matrix, band_length, labels, \n",
    "                       include_length = False, include_hash = False, \n",
    "                       seqs = None, lengths = 0, want_adjacency_matrix = False):\n",
    "\n",
    "    def comparator_length(include_length, a_len, b_len):\n",
    "        # Absolute Threshold\n",
    "        if include_length[1] == 0:\n",
    "            return abs(a_len-b_len) <= include_length[0]\n",
    "        # Percentage Threshold\n",
    "        else:\n",
    "            return abs(a_len-b_len) / max(a_len,b_len) <= include_length[0]\n",
    "\n",
    "    def comparator_hash(include_hash, a, b, a_len, b_len):\n",
    "        min_len = min(a_len, b_len)\n",
    "        num_compare = max(int(min_len * (include_hash / 100)), 1)\n",
    "        indices = np.random.choice(min_len, num_compare, replace=False)\n",
    "        a_subseq = np.array(list(a))[indices]\n",
    "        b_subseq = np.array(list(b))[indices]\n",
    "        return hash(a_subseq.tobytes()) == hash(b_subseq.tobytes())\n",
    "\n",
    "    def connectBucket(bucket, adjacencyMatrix):\n",
    "        for i in range(len(bucket)-1):\n",
    "            for j in range(i+1, len(bucket)):\n",
    "                if include_length and not comparator_length(include_length, lengths[i], lengths[j]):\n",
    "                    continue\n",
    "                if type(include_hash) is int and not comparator_hash(include_hash, seqs[i], seqs[j], lengths[i], lengths[j]):\n",
    "                    continue\n",
    "                adjacencyMatrix[bucket[i],bucket[j]] = True\n",
    "                adjacencyMatrix[bucket[j],bucket[i]] = True\n",
    "        return adjacencyMatrix\n",
    "\n",
    "    firstOcc = np.argmax(labels>1)\n",
    "    adjacencyMatrix = np.zeros((len(labels), len(labels)))\n",
    "\n",
    "    for i in range(signature_matrix.shape[0]//band_length):\n",
    "        buckets = defaultdict(list[int])\n",
    "        startBucket = i*band_length\n",
    "        endBucket = (i+1)*band_length\n",
    "        for j in range(signature_matrix.shape[1]):\n",
    "            buckets[signature_matrix[startBucket:endBucket, j].tobytes()].append(j)\n",
    "        for bucket in buckets.values():\n",
    "            adjacencyMatrix = connectBucket(bucket, adjacencyMatrix)\n",
    "    if want_adjacency_matrix:\n",
    "        return adjacencyMatrix\n",
    "\n",
    "    return tpr_fpr(len(labels), firstOcc, adjacencyMatrix)\n",
    "\n",
    "\"\"\"\n",
    "Generate true positive rate and false positive rate for a given adjacency matrix\n",
    "\"\"\"\n",
    "def tpr_fpr(n, firstOcc, adjacencyMatrix):\n",
    "    trueMask = np.zeros((n , n), dtype = bool)\n",
    "    trueMask[:firstOcc, :firstOcc] = 1\n",
    "    trueMask[firstOcc:, firstOcc:] = 1\n",
    "\n",
    "    true_pos = int(np.sum(adjacencyMatrix, where = trueMask)/2)\n",
    "    tot_pos = int((np.sum(trueMask) - n)/2)\n",
    "    false_pos = int(np.sum(adjacencyMatrix, where = ~trueMask)/2)\n",
    "    tot_neg = int(np.sum(~trueMask)/2)\n",
    "\n",
    "    local_counts = np.array([true_pos, tot_pos, false_pos, tot_neg])\n",
    "\n",
    "    return local_counts\n",
    "\n",
    "\"\"\"\n",
    "Callable function to parallelize banding step\n",
    "    if len(band_size) == 1 then returns adjacency matrices\n",
    "\"\"\"\n",
    "def parallel_regions(signature_matrix_directory, band_sizes = range(1, 500), verbose = 0,\n",
    "                     non_repetitive = False, repetitive = False, \n",
    "                     include_hash = False, include_length = False,\n",
    "                     fastq_file = False):\n",
    "\n",
    "    if fastq_file:\n",
    "        signature_matrix_file = fastq_file.replace(\"fastq\", \"npy\")\n",
    "        adjacency_matrix = test_bands(signature_matrix_directory, signature_matrix_file, band_sizes)\n",
    "        return adjacency_matrix\n",
    "\n",
    "    # Get correct numpy file set\n",
    "    if repetitive or non_repetitive:\n",
    "        def bed_to_npy(bed):\n",
    "            chrom, start, end = bed.split(\"\\t\")\n",
    "            return f\"{chrom}_{int(start)-20}-{int(end)+20}.npy\"\n",
    "        repetitive_regions_file = \"../../../output/analysis/human_chm13v2.0_maskedY_rCRS.trf.bed\"\n",
    "        with open(repetitive_regions_file, \"r\") as f:\n",
    "            repetitive_regions = set([bed_to_npy(x) for x in f.read().splitlines()])\n",
    "    if non_repetitive:\n",
    "        numpy_files = [x for x in os.listdir(signature_matrix_directory) if x not in repetitive_regions]\n",
    "    if repetitive:\n",
    "        numpy_files = [x for x in os.listdir(signature_matrix_directory) if x in repetitive_regions]\n",
    "    if repetitive and non_repetitive or not repetitive and not non_repetitive:\n",
    "        numpy_files = os.listdir(signature_matrix_directory)\n",
    "\n",
    "    inputs = zip(repeat(signature_matrix_directory), \n",
    "                 numpy_files, \n",
    "                 repeat(band_sizes), \n",
    "                 repeat(include_length), \n",
    "                 repeat(include_hash)\n",
    "    )\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "    print(\"Running Parallel Step\")\n",
    "    start = time.time()\n",
    "    outputs = Parallel(n_jobs=num_cores, verbose=verbose)(delayed(test_bands)(i, j, k, l, m) for i, j, k, l, m  in inputs)\n",
    "    print(\"Total time\\t:\", time.time() - start)\n",
    "\n",
    "    counts = outputs[0]\n",
    "    for output in outputs[1:]:\n",
    "        counts += output\n",
    "    return counts\n",
    "\n",
    "\"\"\"\n",
    "Return index of first occurrence of label 2\n",
    "\"\"\"\n",
    "def get_first_occ(labels):\n",
    "    labelSet = set(labels)\n",
    "    firstOcc = [0 for _ in range(len(labelSet))]\n",
    "    for i, item in enumerate(sorted(labelSet)):\n",
    "        firstOcc[i] = labels.index(item)\n",
    "    return firstOcc[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_file = \"chr15_30271921-30272041.fastq\"\n",
    "cosine_signature_matrix_directory = \"../../../output/signatureMtxs_20bp/sketch/1000,21,1\"\n",
    "cosine_band_size = 200\n",
    "\n",
    "euclidean_signature_matrix_directory = \"../../../output/signatureMtxs_20bp/euclidean/1000,21,8,1\"\n",
    "euclidean_band_size = 50\n",
    "\n",
    "adjacency_matrix, labels = parallel_regions(cosine_signature_matrix_directory, cosine_band_size, fastq_file = fastq_file)\n",
    "first_occurrence = get_first_occ(list(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpr: 0.06074766355140187\n",
      "fpr: 0.03619909502262444\n"
     ]
    }
   ],
   "source": [
    "counts = tpr_fpr(len(adjacency_matrix), first_occurrence, adjacency_matrix)\n",
    "print(\"tpr:\", counts[0]/counts[1])\n",
    "print(\"fpr:\", counts[2]/counts[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize a Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
